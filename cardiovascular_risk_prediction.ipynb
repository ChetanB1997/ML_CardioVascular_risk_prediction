{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "private_outputs": true,
      "provenance": [],
      "collapsed_sections": [
        "vncDsAP0Gaoa",
        "g-ATYxFrGrvw",
        "Yfr_Vlr8HBkt",
        "8yEUt7NnHlrM",
        "tEA2Xm5dHt1r",
        "I79__PHVH19G",
        "Ou-I18pAyIpj",
        "fF3858GYyt-u",
        "4_0_7-oCpUZd",
        "hwyV_J3ipUZe",
        "3yB-zSqbpUZe",
        "dEUvejAfpUZe",
        "Fd15vwWVpUZf",
        "bn_IUdTipZyH",
        "49K5P_iCpZyH",
        "Nff-vKELpZyI",
        "kLW572S8pZyI",
        "dWbDXHzopZyI",
        "KH5McJBi2d8v",
        "iW_Lq9qf2h6X",
        "-Kee-DAl2viO",
        "gCX9965dhzqZ",
        "gIfDvo9L0UH2"
      ],
      "gpuType": "T4",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/ChetanB1997/ML_CardioVascular_risk_prediction/blob/main/cardiovascular_risk_prediction.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Project Name**    - Cardiovascular risk prediction\n",
        "\n"
      ],
      "metadata": {
        "id": "vncDsAP0Gaoa"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Project Summary -**"
      ],
      "metadata": {
        "id": "FJNUwmbgGyua"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Heart disease, also known as cardiovascular disease, is a general term that refers to a group of conditions that affect the heart and blood vessels. The most common forms of heart disease include coronary artery disease, heart valve disease, and heart failure.\n",
        "\n",
        "Current practices for the prevention and treatment of heart disease include lifestyle changes such as maintaining a healthy diet, regular exercise, and not smoking. Medications such as statins, blood pressure medications, and anticoagulants are also commonly used to lower the risk of heart disease. In some cases, interventional procedures such as angioplasty or bypass surgery may be necessary to treat advanced cases of heart disease.\n",
        "\n",
        "Background research on heart disease has led to a better understanding of the underlying causes and risk factors for the condition. Some of the major risk factors for heart disease include high blood pressure, high cholesterol, diabetes, smoking, and a family history of the condition. Studies have also shown that certain lifestyle factors, such as diet and physical activity, can have a significant impact on the development of heart disease.\n",
        "\n",
        "Recent research has also focused on identifying new treatments for heart disease, as well as ways to improve the effectiveness of existing treatments. This has led to the development of new medications and procedures, such as minimally invasive surgeries and the use of stem cells to repair damaged heart tissue.\n",
        "\n",
        "Overall, the field of heart disease research is constantly evolving, with new findings and treatments being developed all the time"
      ],
      "metadata": {
        "id": "F6v_1wHtG2nS"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Problem Statement**\n"
      ],
      "metadata": {
        "id": "yQaldy8SH6Dl"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Do classification (Diseased or Not Diseased) on this data and choose the best model with highest accuracy."
      ],
      "metadata": {
        "id": "DpeJGUA3kjGy"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# ***Let's Begin !***"
      ],
      "metadata": {
        "id": "O_i_v8NEhb9l"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## ***1. Know Your Data***"
      ],
      "metadata": {
        "id": "HhfV-JJviCcP"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Import Libraries"
      ],
      "metadata": {
        "id": "Y3lxredqlCYt"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Import Libraries\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "\n",
        "from sklearn.impute import KNNImputer\n",
        "from sklearn.feature_selection import chi2\n",
        "from sklearn.metrics import recall_score\n",
        "from sklearn.model_selection import train_test_split\n",
        "from imblearn.over_sampling import SMOTE\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.metrics import classification_report\n",
        "from sklearn.neighbors import KNeighborsClassifier\n",
        "from sklearn.naive_bayes import GaussianNB\n",
        "from sklearn.model_selection import GridSearchCV\n",
        "from sklearn.model_selection import RepeatedStratifiedKFold\n",
        "from sklearn.tree import DecisionTreeClassifier\n",
        "from sklearn.svm import SVC\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "import xgboost as xgb\n",
        "\n",
        "from prettytable import PrettyTable\n",
        "\n",
        "import warnings\n",
        "warnings.filterwarnings('ignore')\n",
        "\n",
        "%matplotlib inline\n",
        "sns.set()"
      ],
      "metadata": {
        "id": "M8Vqi-pPk-HR"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Dataset Loading"
      ],
      "metadata": {
        "id": "3RnN4peoiCZX"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "id": "vp7Styo37meF"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Load Dataset\n",
        "path = '/content/drive/MyDrive/AlmaBetter/ML capstone /data_cardiovascular_risk.csv'\n",
        "\n",
        "df = pd.read_csv(path , index_col = \"id\")"
      ],
      "metadata": {
        "id": "4CkvbW_SlZ_R"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Dataset First View"
      ],
      "metadata": {
        "id": "x71ZqKXriCWQ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Dataset First Look\n",
        "df.head()"
      ],
      "metadata": {
        "id": "LWNFOSvLl09H"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Dataset Rows & Columns count"
      ],
      "metadata": {
        "id": "7hBIi_osiCS2"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Dataset Rows & Columns count\n",
        "df.shape"
      ],
      "metadata": {
        "id": "Kllu7SJgmLij"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Dataset Information"
      ],
      "metadata": {
        "id": "JlHwYmJAmNHm"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Dataset Info\n",
        "df.info()"
      ],
      "metadata": {
        "id": "e9hRXRi6meOf"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Duplicate Values"
      ],
      "metadata": {
        "id": "35m5QtbWiB9F"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "df.duplicated().value_counts()"
      ],
      "metadata": {
        "id": "apscVUqsCAhs"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Missing Values/Null Values"
      ],
      "metadata": {
        "id": "PoPl-ycgm1ru"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Missing Values/Null Values Count\n",
        "df.isnull().sum()"
      ],
      "metadata": {
        "id": "GgHWkxvamxVg"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df.isna().sum().sum()"
      ],
      "metadata": {
        "id": "aNfdi9anDW9L"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Plotting the heatmap for missing values\n",
        "missing_values = df.isnull()\n",
        "sns.heatmap(missing_values)"
      ],
      "metadata": {
        "id": "3q5wnI3om9sJ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### What did you know about your dataset?"
      ],
      "metadata": {
        "id": "H0kj-8xxnORC"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "The dataset contains 3390 rows and 16 columns. There are no duplicate records, and contains total of 510 missing values."
      ],
      "metadata": {
        "id": "gfoNAAC-nUe_"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## ***2. Understanding Your Variables***"
      ],
      "metadata": {
        "id": "nA9Y7ga8ng1Z"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Dataset Columns\n",
        "df.columns"
      ],
      "metadata": {
        "id": "j7xfkqrt5Ag5"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Dataset Describe\n",
        "df.describe()"
      ],
      "metadata": {
        "id": "DnOaZdaE5Q5t"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Variables Description"
      ],
      "metadata": {
        "id": "PBTbrJXOngz2"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Sex:** male or female (\"M\" or \"F\")\n",
        "\n",
        "**Age:** Age of the patient (Continuous - Although the recorded ages have been truncated to whole numbers, the concept of age is continuous)\n",
        "\n",
        "**Education:** The level of education of the patient (categorical values - 1,2,3,4)\n",
        "\n",
        "**is_smoking:** whether or not the patient is a current smoker (\"YES\" or \"NO\")\n",
        "\n",
        "**Cigs Per Day:** the number of cigarettes that the person smoked on average in one day.(can be considered continuous as one can have any number of cigarettes, even half a cigarette.)\n",
        "\n",
        "**BP Meds:** whether or not the patient was on blood pressure medication (Nominal)\n",
        "\n",
        "**Prevalent Stroke:** whether or not the patient had previously had a stroke (Nominal)\n",
        "\n",
        "**Prevalent Hyp:** whether or not the patient was hypertensive (Nominal)\n",
        "\n",
        "**Diabetes:** whether or not the patient had diabetes (Nominal)\n",
        "\n",
        "**Tot Chol:** total cholesterol level (Continuous)\n",
        "\n",
        "**Sys BP:** systolic blood pressure (Continuous)\n",
        "\n",
        "**Dia BP:** diastolic blood pressure (Continuous)\n",
        "\n",
        "**BMI:** Body Mass Index (Continuous)\n",
        "\n",
        "**Heart Rate:** heart rate (Continuous - In medical research, variables such as heart rate though in fact discrete, yet are considered continuous because of large number of possible values.)\n",
        "\n",
        "**Glucose:** glucose level (Continuous)\n",
        "\n",
        "**TenYearCHD:**10-year risk of coronary heart disease CHD(binary: “1”, means “Yes”, “0” means “No”)"
      ],
      "metadata": {
        "id": "aJV4KIxSnxay"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Check Unique Values for each variable."
      ],
      "metadata": {
        "id": "u3PMJOP6ngxN"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Check Unique Values for each variable.\n",
        "df.nunique()"
      ],
      "metadata": {
        "id": "zms12Yq5n-jE"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 3. ***Data Wrangling***"
      ],
      "metadata": {
        "id": "dauF4eBmngu3"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Data Wrangling Code"
      ],
      "metadata": {
        "id": "bKJF3rekwFvQ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Renaming the columns\n",
        "df.rename(columns={'cigsPerDay':'cigs_per_day','BPMeds':'bp_meds',\n",
        "                   'prevalentStroke':'prevalent_stroke','prevalentHyp':'prevalent_hyp',\n",
        "                   'totChol':'total_cholesterol','sysBP':'systolic_bp','diaBP':'diastolic_bp',\n",
        "                   'BMI':'bmi','heartRate':'heart_rate','TenYearCHD':'ten_year_chd'},\n",
        "          inplace = True)\n"
      ],
      "metadata": {
        "id": "kwkkKUFeLZF9"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Defining 3 lists containing the column names of\n",
        "# a. dependent variables\n",
        "# b. continuous independent variables\n",
        "# c. categorical independent variables\n",
        "# This is defined based on the number of unique values for each attribute\n",
        "\n",
        "dependent_var = ['ten_year_chd']\n",
        "continuous_var = ['age','cigs_per_day','total_cholesterol','systolic_bp', 'diastolic_bp', 'bmi', 'heart_rate', 'glucose']\n",
        "categorical_var = ['education', 'sex', 'is_smoking','bp_meds','prevalent_stroke', 'prevalent_hyp', 'diabetes']"
      ],
      "metadata": {
        "id": "wk-9a2fpoLcV"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Replacing the missing values in the categorical columns with its mode\n",
        "df['education'] = df['education'].fillna(df['education'].mode()[0])\n",
        "df['bp_meds'] = df['bp_meds'].fillna(df['bp_meds'].mode()[0])"
      ],
      "metadata": {
        "id": "GSc1IpclLq3k"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# education distribution after mode imputation\n",
        "df.education.value_counts()"
      ],
      "metadata": {
        "id": "n-YMorOoMRsE"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# bp_meds distribution after mode imputation\n",
        "df.bp_meds.value_counts()"
      ],
      "metadata": {
        "id": "vaInRcL3MRpR"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "###Variable: cigs_per_day"
      ],
      "metadata": {
        "id": "XpdG-yGdhu_G"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Mean and median number of cigarettes per day\n",
        "print(df.cigs_per_day.mean().round(0))\n",
        "print(df.cigs_per_day.median())"
      ],
      "metadata": {
        "id": "qeqkOWUSMRl8"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df[df['cigs_per_day'].isna()]\n"
      ],
      "metadata": {
        "id": "25n7p3F3OAdH"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "here we see fo null values of cigs_per_day column are yes for every person who is smoking.means these all persons are smoker"
      ],
      "metadata": {
        "id": "_LA0SUI0OQ7Q"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "# mean and median number of cigarettes per day for a smoker (excluding non-smokers)\n",
        "a=(df[df['is_smoking']=='YES']['cigs_per_day'].mean())\n",
        "b=(df[df['is_smoking']=='YES']['cigs_per_day'].median())\n",
        "print(\"Mean number of cigarettes for a smoker :\",a)\n",
        "print(\"Median number of cigarettes for a smoker :\",b )"
      ],
      "metadata": {
        "id": "dcySVfehcLOr"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# distribution of number of cigarettes per day for smokers (excluding non-smokers)\n",
        "plt.figure(figsize=(8,5))\n",
        "sns.distplot(df[df['is_smoking']==\"YES\"]['cigs_per_day'])\n",
        "plt.axvline(df[df['is_smoking']==\"YES\"]['cigs_per_day'].mean(), color='orange', linestyle='dashed', linewidth=2)\n",
        "plt.axvline(df[df['is_smoking']==\"YES\"]['cigs_per_day'].median(), color='red', linestyle='dashed', linewidth=2)\n",
        "plt.title('Cigs_per_day for smokers distribution')\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "NlMmGfx9c5ik"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# box plot for the number of cigarettes per day for smokers (excluding non-smokers)\n",
        "plt.figure(figsize=(5,5))\n",
        "sns.boxplot(df[df['is_smoking']==\"YES\"]['cigs_per_day'])"
      ],
      "metadata": {
        "id": "ZsCbkfTle9Wb"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "As the number of cigarettes smoked by the patients who smoke, contains some outliers so we cant use mean to replace the missing values. the missing values in ths cigs_per_day column can be replaced with its median value."
      ],
      "metadata": {
        "id": "4xIxPikbfZgA"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "df['cigs_per_day'] = df['cigs_per_day'].fillna(df[df['is_smoking']==\"YES\"]['cigs_per_day'].median())"
      ],
      "metadata": {
        "id": "T43-7YiufY__"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#converting this column into label (1,0)\n",
        "df['is_smoking'] = np.where(df['is_smoking'] == 'YES',1,0)"
      ],
      "metadata": {
        "id": "U8coEubGgjPI"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "###Variable:sex"
      ],
      "metadata": {
        "id": "ufeeWjKSwN_b"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#Label Encoding Categorical columns sex and is_smoking\n",
        "df['sex'] = df['sex'].apply(lambda x: 1 if x=='M' else 0)\n"
      ],
      "metadata": {
        "id": "Xm0VCMCDwT2T"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "###Variable: total_cholestrol, bmi, heart_rate"
      ],
      "metadata": {
        "id": "K87MQi6Vh4iz"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "variables = ['total_cholesterol', 'bmi', 'heart_rate']\n",
        "num_plots = len(variables)\n",
        "\n",
        "plt.figure(figsize=(12, 5))  # Adjust the figure size as needed\n",
        "\n",
        "for idx, i in enumerate(variables):\n",
        "    plt.subplot(1, num_plots, idx + 1)\n",
        "    sns.distplot(df[i])\n",
        "    plt.axvline(df[i].mean(), color='orange', linestyle='dashed', linewidth=2)\n",
        "    plt.axvline(df[i].median(), color='red', linestyle='dashed', linewidth=2)\n",
        "    plt.title(i + ' distribution')\n",
        "\n",
        "plt.tight_layout()  # To ensure proper spacing between subplots\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "6-6pzVcqs4Pb"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "we see from graph all 3 column data is Positively skewed."
      ],
      "metadata": {
        "id": "IpiNLB9-uwTL"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "# Checking outliers in total_cholesterol, bmi, heart_rate columns\n",
        "var2=['total_cholesterol','bmi','heart_rate']\n",
        "num_plots = len(var2)\n",
        "\n",
        "plt.figure(figsize=(12, 5))\n",
        "\n",
        "for idx, i in enumerate(var2):\n",
        "  plt.subplot(1, num_plots, idx + 1)\n",
        "  sns.boxplot(df[i])\n",
        "  plt.title(i+' boxplot')\n",
        "\n",
        "plt.tight_layout()  # To ensure proper spacing between subplots\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "nUVHopc3s4LO"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "All 3 columns contain the outliers"
      ],
      "metadata": {
        "id": "tRFTphXiuk0J"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Mean and median for total_cholesterol\n",
        "df.total_cholesterol.mean(),df.total_cholesterol.median()"
      ],
      "metadata": {
        "id": "WERoDZo7s4Hm"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df.bmi.mean(), df.bmi.median()"
      ],
      "metadata": {
        "id": "RIoauoInvFFR"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df.heart_rate.mean(), df.heart_rate.median()"
      ],
      "metadata": {
        "id": "ZIIXuqvjvE5l"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Here we see the data is positively skewed as well it has many outliers so it will be good to use median for all missing values from this tables."
      ],
      "metadata": {
        "id": "LbyXE7I1olp8"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Imputing missing values in the total_cholesterol, bmi, and heart_rate with their medain values\n",
        "df['total_cholesterol'] = df['total_cholesterol'].fillna(df['total_cholesterol'].median())\n",
        "df['bmi'] = df['bmi'].fillna(df['bmi'].median())\n",
        "df['heart_rate'] = df['heart_rate'].fillna(df['heart_rate'].median())"
      ],
      "metadata": {
        "id": "W6_U4a-3vsOB"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "###Variable: Glucose"
      ],
      "metadata": {
        "id": "zUKed8aownKh"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "df.glucose.isna().sum()"
      ],
      "metadata": {
        "id": "grcMSR-6wl_p"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# distribution of glucose\n",
        "plt.figure(figsize=(8,5))\n",
        "sns.distplot(df['glucose'])\n",
        "plt.axvline(df['glucose'].mean(), color='orange', linestyle='dashed', linewidth=2)\n",
        "plt.axvline(df['glucose'].median(), color='red', linestyle='dashed', linewidth=2)\n",
        "plt.title('Glucose distribution')\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "zUop2Jc5wzoB"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "The glucose is positively skewed"
      ],
      "metadata": {
        "id": "MZ57jC9kw9Ta"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "# Outliers in glucose\n",
        "plt.figure(figsize=(5,5))\n",
        "sns.boxplot(df['glucose'])\n",
        "plt.title('Glucose boxplot')"
      ],
      "metadata": {
        "id": "4c1dYibpwzjt"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "glucose has many outliers."
      ],
      "metadata": {
        "id": "u-q4NvLOxMI5"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "df.glucose.mean(),df.glucose.median(),df.glucose.mode()"
      ],
      "metadata": {
        "id": "QnHgKQ53wzeO"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "-Here 304 nearly 9 to 10 % values of data are missing.\n",
        "\n",
        "-if we replace those values with mean /median it may create biased data.\n",
        "\n",
        "-To avoid this we can impute the missing values using KNN imputer."
      ],
      "metadata": {
        "id": "FEbbkSqjyayL"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Using KNN imputer with K=10\n",
        "imputer = KNNImputer(n_neighbors=10)\n",
        "imputed = imputer.fit_transform(df)\n",
        "df = pd.DataFrame(imputed, columns=df.columns)"
      ],
      "metadata": {
        "id": "TAbB3s72yzOo"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df.info()\n"
      ],
      "metadata": {
        "id": "RCFgiMlfyzJv"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "###What all manipulations have you done and insights you found?"
      ],
      "metadata": {
        "id": "yVa8uDYhy_j5"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "For categorical variable: replaced the null values with mode values\n",
        "\n",
        "For Continuos variable:\n",
        "\n",
        "-Total_cholestrol, BMI, hearRate: replaced the null values with median values\n",
        "\n",
        "-cigsPerDay : replaced the null values with median value of people who smoke\n",
        "\n",
        "-glucose : To avoid bias due to high number of null values, replaced null values with KNN Imputer."
      ],
      "metadata": {
        "id": "UWLZ8rv6zNSs"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# changing datatypes\n",
        "df = df.astype({'age': int, 'education':int,'sex':int,'is_smoking':int,'cigs_per_day':int,\n",
        "               'bp_meds':int,'prevalent_stroke':int,'prevalent_hyp':int,'diabetes':int,\n",
        "               'total_cholesterol':float,'systolic_bp':float,'diastolic_bp':float,\n",
        "               'bmi':float,'heart_rate':float,'glucose':float,'ten_year_chd':int})"
      ],
      "metadata": {
        "id": "U8dM_9mGzsxW"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## ***4. Data Vizualization, Storytelling & Experimenting with charts : Understand the relationships between variables***"
      ],
      "metadata": {
        "id": "GF8Ens_Soomf"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Chart - 1"
      ],
      "metadata": {
        "id": "0wOQAZs5pc--"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Chart - 1 visualization code\n",
        "my_palette = {0 : 'orange' , 1 : 'teal'}\n",
        "plt.figure(figsize = (8,8))\n",
        "sns.countplot(x = df['diabetes'], hue = df['ten_year_chd'], palette = my_palette)\n",
        "plt.title(\"Are diabetic patients at more risk of coronary heart disease?\")\n",
        "plt.legend(['No Risk','At Risk'])\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "7v_ESjsspbW7"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### 1. Why did you pick the specific chart?"
      ],
      "metadata": {
        "id": "K5QZ13OEpz2H"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "The diebetic petients are at risk to cardiovascular risk."
      ],
      "metadata": {
        "id": "XESiWehPqBRc"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### 2. What is/are the insight(s) found from the chart?"
      ],
      "metadata": {
        "id": "lQ7QKXXCp7Bj"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "yes, here diebetic patient count is very less as compaired to normal but diebetic patients are having 50 % chances of getting the risk."
      ],
      "metadata": {
        "id": "C_j1G7yiqdRP"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Chart - 2"
      ],
      "metadata": {
        "id": "KSlN3yHqYklG"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Chart - 2 visualization code\n",
        "my_palette = {0 : 'orange' , 1 : 'teal'}\n",
        "plt.figure(figsize = (8,8))\n",
        "sns.countplot(x = df['is_smoking'], hue = df['ten_year_chd'], palette = my_palette)\n",
        "plt.title(\"Are smokers at more risk of CHD ?\")\n",
        "plt.legend(['No Risk','At Risk'])\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "R4YgtaqtYklH"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### 1. Why did you pick the specific chart?"
      ],
      "metadata": {
        "id": "t6dVpIINYklI"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "to check if smocking affect the cardiovascular risk"
      ],
      "metadata": {
        "id": "5aaW0BYyYklI"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### 2. What is/are the insight(s) found from the chart?"
      ],
      "metadata": {
        "id": "ijmpgYnKYklI"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "number of smokers at risk are slightly more than non smokers at risk of CHD"
      ],
      "metadata": {
        "id": "PSx9atu2YklI"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Chart - 3"
      ],
      "metadata": {
        "id": "EM7whBJCYoAo"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Chart - 3 visualization code\n",
        "plt.figure(figsize=(14,8))\n",
        "ax=sns.countplot(x='age', hue='ten_year_chd', data=df)\n",
        "ax.set_xlabel( \"AgeCategory\")\n",
        "ax.set_ylabel( \"AgeCategory Count\")\n",
        "ax.set_title(  \"AgeCategory wise HeartDisease Tendency\")\n",
        "for i in ax.containers:\n",
        "  ax.bar_label(i)\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "t6GMdE67YoAp"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Here we see the age wise count of peoples having CHD. the age between 51-63 having more risk of CHD"
      ],
      "metadata": {
        "id": "uSOrYHx03_X_"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Chart - 4"
      ],
      "metadata": {
        "id": "4Of9eVA-YrdM"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import seaborn as sns\n",
        "\n",
        "# Assuming you have imported the required libraries and loaded your DataFrame 'df'\n",
        "# Also, make sure you have the list of categorical variables as 'categorical_var'\n",
        "\n",
        "num_plots = len(categorical_var)\n",
        "num_rows = 4\n",
        "num_cols = 2\n",
        "\n",
        "fig, axs = plt.subplots(num_rows, num_cols, figsize=(12,15))\n",
        "\n",
        "# Add space between each plot\n",
        "plt.subplots_adjust(hspace=0.5, wspace=0.3)\n",
        "\n",
        "for idx, i in enumerate(categorical_var):\n",
        "    row = idx // num_cols\n",
        "    col = idx % num_cols\n",
        "    p = sns.countplot(data=df, x=i, ax=axs[row, col])\n",
        "    axs[row, col].set_xlabel(i)\n",
        "    axs[row, col].set_title(i + ' distribution'+ '\\n')\n",
        "    for patch in p.patches:\n",
        "        p.annotate(f'{patch.get_height()}', (patch.get_x() + patch.get_width() / 2., patch.get_height()), ha='center', va='center', xytext=(0,5), textcoords='offset points')\n",
        "\n",
        "# To remove any extra empty subplots if there are fewer categorical variables than the grid size\n",
        "for i in range(len(categorical_var), num_rows * num_cols):\n",
        "    fig.delaxes(axs.flatten()[i])\n"
      ],
      "metadata": {
        "id": "irlUoxc8YrdO"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Summary:\n",
        "\n",
        "Majority of the patients belong to the education level 1, followed by 2, 3, and 4 respectively.\n",
        "\n",
        "There are more female patients compared to male patients.\n",
        "\n",
        "Almost half the patients are smokers.\n",
        "\n",
        "100 patients under the study are undertaking blood pressure medication.\n",
        "\n",
        "22 patients under the study have experienced a stroke.\n",
        "\n",
        "1069 patients have hypertension.\n",
        "\n",
        "87 patients have diabetes."
      ],
      "metadata": {
        "id": "aJRCwT6DYrdO"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Chart - 5"
      ],
      "metadata": {
        "id": "bamQiAODYuh1"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Chart - 5 visualization code\n",
        "\n",
        "plt.figure(figsize=(8, 8))\n",
        "sns.boxplot(x='ten_year_chd', y='systolic_bp', data=df, palette=my_palette)\n",
        "plt.title(\"Are patients with systolic BP at risk of CHD?\")\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "TIJwrbroYuh3"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Chart - 6"
      ],
      "metadata": {
        "id": "OH-pJp9IphqM"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Chart - 6 visualization code\n",
        "plt.figure(figsize = (8,8))\n",
        "sns.boxplot(x='ten_year_chd',y='diastolic_bp', data=df, palette = my_palette)\n",
        "plt.title(\"Are patients with Diastolic BP at risk of CHD?\")\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "kuRf4wtuphqN"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Chart - 7"
      ],
      "metadata": {
        "id": "PIIx-8_IphqN"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Chart - 7 visualization code\n",
        "for i in ['total_cholesterol','bmi','heart_rate']:\n",
        "  plt.figure(figsize=(6,4))\n",
        "  sns.distplot(df[i])\n",
        "  plt.axvline(df[i].mean(), color='magenta', linestyle='dashed', linewidth=2)\n",
        "  plt.axvline(df[i].median(), color='cyan', linestyle='dashed', linewidth=2)\n",
        "  plt.title(i+' distribution')\n",
        "  plt.show()"
      ],
      "metadata": {
        "id": "lqAIGUfyphqO"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Chart - 8"
      ],
      "metadata": {
        "id": "BZR9WyysphqO"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Chart - 8 visualization code\n",
        "def heartRate_data(row):\n",
        "    if row['heart_rate'] <= 59:\n",
        "        value = 'Low'\n",
        "    elif row['heart_rate'] < 100:\n",
        "        value = 'Normal'\n",
        "    else:\n",
        "        value = \"High\"\n",
        "\n",
        "    return value"
      ],
      "metadata": {
        "id": "TdPTWpAVphqO"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "df['heartRateLabel'] = df.apply(heartRate_data, axis = 1)"
      ],
      "metadata": {
        "id": "ZPlm4EGfFcSW"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df['heartRateLabel'].value_counts"
      ],
      "metadata": {
        "id": "B3fdH8B9F2-f"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "plt.figure(figsize = (8,8))\n",
        "my_palette = {0 : 'orange' , 1 : 'teal'}\n",
        "sns.countplot(x = df['heartRateLabel'], hue = df['ten_year_chd'], palette = my_palette)\n",
        "plt.title(\"Is Heart rate is responsible for CHD ?? \")\n",
        "plt.legend(['No Risk','At Risk'])\n",
        "plt.show()\n"
      ],
      "metadata": {
        "id": "yjYyJrw9F7Ug"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Chart - 9"
      ],
      "metadata": {
        "id": "YJ55k-q6phqO"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Chart - 9 visualization code\n",
        "plt.figure(figsize = (8,8))\n",
        "my_palette = {0 : 'orange' , 1 : 'teal'}\n",
        "sns.countplot(x = df['prevalent_stroke'], hue = df['ten_year_chd'], palette = my_palette)\n",
        "plt.title(\"Whether a person who had a stroke earlier more prone to CHD?? \")\n",
        "plt.legend(['No Risk' , 'At Risk'])\n",
        "plt.show()\n"
      ],
      "metadata": {
        "id": "B2aS4O1ophqO"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Chart - 14 - Correlation Heatmap"
      ],
      "metadata": {
        "id": "NC_X3p0fY2L0"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Correlation Heatmap visualization code\n",
        "\n",
        "# Updated correlations\n",
        "plt.figure(figsize=(12,6))\n",
        "plt.title('Correlation Analysis')\n",
        "correlation = df[continuous_var].corr()\n",
        "sns.heatmap(abs(correlation), annot=True, cmap='coolwarm')\n"
      ],
      "metadata": {
        "id": "xyC9zolEZNRQ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## ***5. Hypothesis Testing***"
      ],
      "metadata": {
        "id": "g-ATYxFrGrvw"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Based on your chart experiments, define three hypothetical statements from the dataset. In the next three questions, perform hypothesis testing to obtain final conclusion about the statements through your code and statistical testing."
      ],
      "metadata": {
        "id": "Yfr_Vlr8HBkt"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Answer Here."
      ],
      "metadata": {
        "id": "-7MS06SUHkB-"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Hypothetical Statement - 1"
      ],
      "metadata": {
        "id": "8yEUt7NnHlrM"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### 1. State Your research hypothesis as a null hypothesis and alternate hypothesis."
      ],
      "metadata": {
        "id": "tEA2Xm5dHt1r"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Answer Here."
      ],
      "metadata": {
        "id": "HI9ZP0laH0D-"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### 2. Perform an appropriate statistical test."
      ],
      "metadata": {
        "id": "I79__PHVH19G"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Perform Statistical Test to obtain P-Value"
      ],
      "metadata": {
        "id": "oZrfquKtyian"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### Which statistical test have you done to obtain P-Value?"
      ],
      "metadata": {
        "id": "Ou-I18pAyIpj"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Answer Here."
      ],
      "metadata": {
        "id": "s2U0kk00ygSB"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### Why did you choose the specific statistical test?"
      ],
      "metadata": {
        "id": "fF3858GYyt-u"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Answer Here."
      ],
      "metadata": {
        "id": "HO4K0gP5y3B4"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Hypothetical Statement - 2"
      ],
      "metadata": {
        "id": "4_0_7-oCpUZd"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### 1. State Your research hypothesis as a null hypothesis and alternate hypothesis."
      ],
      "metadata": {
        "id": "hwyV_J3ipUZe"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Answer Here."
      ],
      "metadata": {
        "id": "FnpLGJ-4pUZe"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### 2. Perform an appropriate statistical test."
      ],
      "metadata": {
        "id": "3yB-zSqbpUZe"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Perform Statistical Test to obtain P-Value"
      ],
      "metadata": {
        "id": "sWxdNTXNpUZe"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### Which statistical test have you done to obtain P-Value?"
      ],
      "metadata": {
        "id": "dEUvejAfpUZe"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Answer Here."
      ],
      "metadata": {
        "id": "oLDrPz7HpUZf"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### Why did you choose the specific statistical test?"
      ],
      "metadata": {
        "id": "Fd15vwWVpUZf"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Answer Here."
      ],
      "metadata": {
        "id": "4xOGYyiBpUZf"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Hypothetical Statement - 3"
      ],
      "metadata": {
        "id": "bn_IUdTipZyH"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### 1. State Your research hypothesis as a null hypothesis and alternate hypothesis."
      ],
      "metadata": {
        "id": "49K5P_iCpZyH"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Answer Here."
      ],
      "metadata": {
        "id": "7gWI5rT9pZyH"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### 2. Perform an appropriate statistical test."
      ],
      "metadata": {
        "id": "Nff-vKELpZyI"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Perform Statistical Test to obtain P-Value"
      ],
      "metadata": {
        "id": "s6AnJQjtpZyI"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### Which statistical test have you done to obtain P-Value?"
      ],
      "metadata": {
        "id": "kLW572S8pZyI"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Answer Here."
      ],
      "metadata": {
        "id": "ytWJ8v15pZyI"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### Why did you choose the specific statistical test?"
      ],
      "metadata": {
        "id": "dWbDXHzopZyI"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Answer Here."
      ],
      "metadata": {
        "id": "M99G98V6pZyI"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## ***6. Feature Engineering & Data Pre-processing***"
      ],
      "metadata": {
        "id": "yLjJCtPM0KBk"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "###handling muticoliniarity\n"
      ],
      "metadata": {
        "id": "6LRfpijt0SPY"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "The variables systolic BP and diastolic BP are highly correlated."
      ],
      "metadata": {
        "id": "am5_6ubD0gQy"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "print(df['systolic_bp'].min(),df['systolic_bp'].max())\n",
        "print(df['diastolic_bp'].min(),df['diastolic_bp'].max())"
      ],
      "metadata": {
        "id": "6FpIa1Ii0PyH"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Pulse Pressure = Systolic BP - Diastolic BP"
      ],
      "metadata": {
        "id": "H9g4gOTn0tHz"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "# Creating a new column pulse_pressure\n",
        "# and dropping systolic_bp and diastolic_bp\n",
        "\n",
        "df['pulse_pressure'] = df['systolic_bp']-df['diastolic_bp']\n",
        "df.drop('systolic_bp',axis=1,inplace=True)\n",
        "df.drop('diastolic_bp',axis=1,inplace=True)"
      ],
      "metadata": {
        "id": "ZEuXuvy003Cs"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df.columns"
      ],
      "metadata": {
        "id": "Z47C9RyJ06v1"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "continuous_var.remove('systolic_bp')\n",
        "continuous_var.remove('diastolic_bp')\n",
        "continuous_var.append('pulse_pressure')\n"
      ],
      "metadata": {
        "id": "RcO8Hr791BZI"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Analyzing the distribution of pulse_pressure\n",
        "plt.figure(figsize=(10,5))\n",
        "sns.distplot(df['pulse_pressure'])\n",
        "plt.axvline(df['pulse_pressure'].mean(), color='magenta', linestyle='dashed', linewidth=2)\n",
        "plt.axvline(df['pulse_pressure'].median(), color='cyan', linestyle='dashed', linewidth=2)\n",
        "plt.title('Pulse Pressure Distribution')\n"
      ],
      "metadata": {
        "id": "O6seC6JJ1G3B"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# dropping is_smoking\n",
        "df.drop('is_smoking',axis=1,inplace=True)"
      ],
      "metadata": {
        "id": "9OkeKAIv1SAF"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df.drop(columns=['heartRateLabel'], inplace=True)"
      ],
      "metadata": {
        "id": "ubpngF4W-SWN"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "# dropping is smoking\n",
        "categorical_var.remove('is_smoking')\n",
        "categorical_var"
      ],
      "metadata": {
        "id": "X6lfuXV51VPS"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "###outlier analysis\n"
      ],
      "metadata": {
        "id": "c9kM4W2ePHkd"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "fig, axes = plt.subplots(nrows=2, ncols=4, figsize=(12,12))\n",
        "\n",
        "# Flattening the axes for easier iteration\n",
        "axes = axes.flatten()\n",
        "\n",
        "# Looping through each continuous variable and plotting the boxplot\n",
        "for i, col in enumerate(continuous_var):\n",
        "    sns.boxplot(y=col, x=dependent_var[0], data=df, ax=axes[i])\n",
        "    axes[i].set_title(col + ' boxplot')\n",
        "\n",
        "# Tight layout to avoid overlapping titles and labels\n",
        "plt.tight_layout()\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "qWEoKPXMPrlR"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "here are outliers in the data, the effect of the outliers can be reduced to some extent by transforming it.\n",
        "Once the data is transformed, if outliers beyond 3 standard deviations from the mean still remain, then they can be imputed with its respective median value.\n",
        "This is done on the train data only to prevent data leakage."
      ],
      "metadata": {
        "id": "S_4aJhveQUbP"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "old_df= df.copy()"
      ],
      "metadata": {
        "id": "IDG43gNxsZ56"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# skewness along the index axis\n",
        "(df[continuous_var]).skew(axis = 0)"
      ],
      "metadata": {
        "id": "wp5zpJH12kfK"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "np.log10(df[continuous_var]+1).skew(axis = 0)"
      ],
      "metadata": {
        "id": "hrd2T4mr2kaf"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "We can clearly see that by log transformation of the continuous variables, we are able to reduce it's skew to some extent."
      ],
      "metadata": {
        "id": "pavBD4HF3BTD"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Implementing log transformation on continuous variables\n",
        "\n",
        "df['age']                   = np.log10(df['age']+1)\n",
        "df['cigs_per_day']          = np.log10(df['cigs_per_day']+1)\n",
        "df['total_cholesterol']     = np.log10(df['total_cholesterol']+1)\n",
        "df['bmi']                   = np.log10(df['bmi']+1)\n",
        "df['heart_rate']            = np.log10(df['heart_rate']+1)\n",
        "df['glucose']               = np.log10(df['glucose']+1)\n",
        "df['pulse_pressure']        = np.log10(df['pulse_pressure']+1)"
      ],
      "metadata": {
        "id": "dooYoukW29pc"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "for col in continuous_var:\n",
        "    fig, axes = plt.subplots(1, 2, figsize=(12, 4))  # Create a figure with two subplots side by side\n",
        "\n",
        "    sns.distplot(old_df[col], ax=axes[0], label='old_df', color='blue')  # Plot on the first subplot\n",
        "    sns.distplot(df[col], ax=axes[1], label='df', color='orange')        # Plot on the second subplot\n",
        "\n",
        "    axes[0].axvline(old_df[col].mean(), color='magenta', linestyle='dashed', linewidth=2)  # Add mean line to the first subplot\n",
        "    axes[0].axvline(old_df[col].median(), color='cyan', linestyle='dashed', linewidth=2) # Add median line to the first subplot\n",
        "\n",
        "    axes[1].axvline(df[col].mean(), color='magenta', linestyle='dashed', linewidth=2)     # Add mean line to the second subplot\n",
        "    axes[1].axvline(df[col].median(), color='cyan', linestyle='dashed', linewidth=2)      # Add median line to the second subplot\n",
        "\n",
        "    axes[0].set_title(col + ' distribution (old_df)')  # Set title for the first subplot\n",
        "    axes[1].set_title(col + ' distribution (df)')      # Set title for the second subplot\n",
        "\n",
        "    axes[0].legend()  # Show legend for the first subplot\n",
        "    axes[1].legend()  # Show legend for the second subplot\n",
        "\n",
        "    plt.show()"
      ],
      "metadata": {
        "id": "bO9IJzR3s7ll"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Except cigs_per_day, we have successfully been able to reduce the skewness in the continuous variables. Now these distributions are closer to symmetric distribution."
      ],
      "metadata": {
        "id": "etf2So8Z3Wnn"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "##preprocessing\n"
      ],
      "metadata": {
        "id": "-uc1aqZi3tC6"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Defining dependent and independent variables\n",
        "X = df.drop('ten_year_chd',axis=1)\n",
        "y = df[dependent_var]"
      ],
      "metadata": {
        "id": "6DRnffBt3qda"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "###Evalution metrices\n"
      ],
      "metadata": {
        "id": "LW99khyu4DGa"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Since the data we are dealing with is unbalanced, accuracy may not be the best evaluation metric to evaluate the model performance.\n",
        "\n",
        "Also, since we are dealing with data related to healthcare, False Negatives are of higher concern than False Positive\n",
        "In other words, it doesn’t matter whether we raise a false alarm but the actual positive cases should not go undetected\n",
        "\n",
        "Considering these points in mind, it is decided that we use Recall as the model evaluation metric."
      ],
      "metadata": {
        "id": "gcTH1klV4IIK"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "# function to get recall score\n",
        "def recall(actual,predicted):\n",
        "  '''\n",
        "  recall(actual,predicted)\n",
        "  '''\n",
        "  return recall_score(y_true=actual, y_pred=predicted, average='binary')"
      ],
      "metadata": {
        "id": "9cOOLmAr4X7j"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 8. Data Splitting"
      ],
      "metadata": {
        "id": "BhH2vgX9EjGr"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Split your data to train and test. Choose Splitting ratio wisely.\n",
        "# train test split\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=0, stratify=y, shuffle=True)"
      ],
      "metadata": {
        "id": "0CTyd2UwEyNM"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "y_train.value_counts() , y_test.value_counts()"
      ],
      "metadata": {
        "id": "slgNI_l24kjA"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "The train and test set contain almost equal proportion of results."
      ],
      "metadata": {
        "id": "JEk1_8hA5_Uv"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### What data splitting ratio have you used and why?"
      ],
      "metadata": {
        "id": "qjKvONjwE8ra"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Since the data is imbalanced, stratified split was employed to get almost equal proportion of dependent variables in the train and test sets.\n"
      ],
      "metadata": {
        "id": "Y2lJ8cobFDb_"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 9. Handling Imbalanced Dataset"
      ],
      "metadata": {
        "id": "P1XJ9OREExlT"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### Do you think the dataset is imbalanced? Explain Why."
      ],
      "metadata": {
        "id": "VFOzZv6IFROw"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Imputing the outliers in 'total_cholesterol', 'bmi', 'heart_rate', 'glucose', 'pulse_pressure' beyond 3 standard deviations from the mean with its median value."
      ],
      "metadata": {
        "id": "GeKDIv7pFgcC"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Handling Imbalanced Dataset (If needed)\n",
        "for i in ['total_cholesterol', 'bmi', 'heart_rate', 'glucose','pulse_pressure']:\n",
        "  upper_lim = X_train[i].mean() + 3 * X_train[i].std()\n",
        "  lower_lim = X_train[i].mean() - 3 * X_train[i].std()\n",
        "  X_train.loc[(X_train[i] > upper_lim),i] = X_train[i].median()\n",
        "  X_train.loc[(X_train[i] < lower_lim),i] = X_train[i].median()\n"
      ],
      "metadata": {
        "id": "nQsRhhZLFiDs"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "X_train[continuous_var].skew(axis = 0)"
      ],
      "metadata": {
        "id": "FR-LXZkO6rpo"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "We were successsful in handling outliers in the train data, and thereby reducing skew."
      ],
      "metadata": {
        "id": "1nsdE8gk6wj5"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "###oversampling"
      ],
      "metadata": {
        "id": "e-pleBbv7HDl"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "y_train.value_counts().plot(kind='bar', title='Target variable before SMOTE')"
      ],
      "metadata": {
        "id": "kf2w4_tm7J41"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### What technique did you use to handle the imbalance dataset and why? (If needed to be balanced)"
      ],
      "metadata": {
        "id": "TIqpNgepFxVj"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Since we are dealing with unbalanced data, ie, only ~15% of the patients were diagnosed with coronary heart disease, we oversample the train dataset using SMOTE (Synthetic Minority Oversampling Technique)."
      ],
      "metadata": {
        "id": "qbet1HwdGDTz"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "X_train"
      ],
      "metadata": {
        "id": "99qPXJ0O9gJd"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Oversampling using SMOTE\n",
        "smote = SMOTE()\n",
        "\n",
        "# fit predictor and target variable\n",
        "X_smote, y_smote = smote.fit_resample(X_train, y_train)\n",
        "\n",
        "print('Samples in the original dataset', len(y_train))\n",
        "print('Samples in the resampled dataset', len(y_smote))\n"
      ],
      "metadata": {
        "id": "TbBp8_kI7ZSd"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# visualize the target variable after SMOTE\n",
        "y_smote.value_counts().plot(kind='bar', title='Target variable after SMOTE')"
      ],
      "metadata": {
        "id": "G5rRocer-opF"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "We have successfully oversampled the minority class using SMOTE. Now the model we build will be able to learn from both the classes without any bias."
      ],
      "metadata": {
        "id": "zCcU7Qee-ssz"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "##scaling"
      ],
      "metadata": {
        "id": "ROhMRcA6_XyZ"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Since the predictions from the distance based models will get affected if the attributes are in different ranges, we need to scale them.\n",
        "\n",
        "We can use StandardScaler to scale down the variables.\n",
        "The results obtained from scaling can be stored and used while building those models.\n",
        "\n",
        "Tree algorithms do not necessarily require scaling."
      ],
      "metadata": {
        "id": "0aiqEHw2_enR"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Scaling data\n",
        "scaler = StandardScaler()\n",
        "\n",
        "X_train_scaled = scaler.fit_transform(X_train)\n",
        "X_smote_scaled = scaler.fit_transform(X_smote)\n",
        "X_test_scaled = scaler.transform(X_test)\n",
        "\n",
        "# Converting array to dataframe\n",
        "X_train_scaled = pd.DataFrame(X_train_scaled,columns=X_train.columns)\n",
        "X_smote_scaled = pd.DataFrame(X_smote_scaled,columns=X_smote.columns)\n",
        "X_test_scaled = pd.DataFrame(X_test_scaled,columns=X_test.columns)"
      ],
      "metadata": {
        "id": "ypnmKf94_iCP"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Scaled train values\n",
        "X_train_scaled.head()"
      ],
      "metadata": {
        "id": "p-YPKFm7_h-m"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# scaled SMOTE values\n",
        "X_smote_scaled.head()"
      ],
      "metadata": {
        "id": "ptcjEZGB_uHS"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# scaled test values\n",
        "X_test_scaled.head()"
      ],
      "metadata": {
        "id": "Idw_rwFT_4rh"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## ***7. ML Model Implementation***"
      ],
      "metadata": {
        "id": "VfCC591jGiD4"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### ML Model - 1 :Linear Regression"
      ],
      "metadata": {
        "id": "OB4l2ZhMeS1U"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# ML Model - 1 Implementation\n",
        "lr_model = LogisticRegression()\n",
        "\n",
        "# Fit the Algorithm\n",
        "lr_model.fit(X_smote_scaled, y_smote)\n",
        "\n",
        "# Predict on the model\n",
        "lr_train_pred = lr_model.predict(X_smote_scaled)"
      ],
      "metadata": {
        "id": "7ebyywQieS1U"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# training set recall\n",
        "lr_train_recall = recall(y_smote,lr_train_pred)\n",
        "lr_train_recall"
      ],
      "metadata": {
        "id": "KIPf0vfLATAT"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Test predictions\n",
        "lr_test_pred = lr_model.predict(X_test_scaled)\n",
        "\n",
        "# training set recall\n",
        "lr_test_recall = recall(y_test,lr_test_pred)\n",
        "lr_test_recall"
      ],
      "metadata": {
        "id": "1V228abvAYvl"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Classification report\n",
        "print(classification_report(y_test,lr_test_pred))"
      ],
      "metadata": {
        "id": "MSJdtqttAmbS"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Confusion matrix\n",
        "from sklearn.metrics import confusion_matrix as cm\n",
        "from sklearn.metrics import ConfusionMatrixDisplay as cmd\n",
        "lr_confusion_matrix = cm(y_test, lr_test_pred)\n",
        "cm_display = cmd(confusion_matrix = lr_confusion_matrix, display_labels = [False, True])\n",
        "\n",
        "plt.figure(figsize=(4, 4))\n",
        "font = {'family' : 'DejaVu Sans',\n",
        "        'weight' : 'bold',\n",
        "        'size'   : 22}\n",
        "plt.rc('font', **font)\n",
        "\n",
        "cm_display.plot(cmap='Oranges')\n",
        "plt.title('Confusion matrix: LOGISTIC REGRESSION')\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "RrFHzFuTA1Aq"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "False negatives obtained after using logistic regression: 50"
      ],
      "metadata": {
        "id": "5ALlh8x6BCWK"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### ML Model - 2 : K nearest neighbours"
      ],
      "metadata": {
        "id": "dJ2tPlVmpsJ0"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Value of k taken upto sqrt(n)\n",
        "# Where n is no of records in the train dataset\n",
        "# sqrt(4030) = 63.48\n",
        "knn_test_res = []\n",
        "knn_train_res = []\n",
        "for k in range(1,65):\n",
        "  knn_model = KNeighborsClassifier(n_neighbors=k)\n",
        "  knn_model.fit(X_smote_scaled, y_smote)\n",
        "  knn_train_pred = knn_model.predict(X_smote_scaled)\n",
        "  knn_train_recall = recall(y_smote,knn_train_pred)\n",
        "  knn_test_pred = knn_model.predict(X_test_scaled)\n",
        "  knn_test_recall = recall(y_test,knn_test_pred)\n",
        "  knn_test_res.append(knn_test_recall)\n",
        "  knn_train_res.append(knn_train_recall)"
      ],
      "metadata": {
        "id": "4jyIB5PhB_En"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Plotting the train and test recalls for different values of k\n",
        "plt.figure(figsize=(10,5))\n",
        "x_ = range(1,65)\n",
        "y1 = knn_train_res\n",
        "y2 = knn_test_res\n",
        "plt.plot(x_, y1, label='Train Recall')\n",
        "plt.plot(x_, y2, label = 'Test Recall')\n",
        "plt.xlabel('K')\n",
        "plt.ylabel('Recall')\n",
        "plt.legend()\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "M2EE5hmhC5xo"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "best_k = knn_test_res.index(max(knn_test_res))+1\n",
        "best_k"
      ],
      "metadata": {
        "id": "QMnbyr9ADJNR"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# building knn model with best parameters\n",
        "knn_model = KNeighborsClassifier(n_neighbors=best_k)\n"
      ],
      "metadata": {
        "id": "4MCTI9q9DJJN"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# training the model\n",
        "knn_model.fit(X_smote_scaled, y_smote)"
      ],
      "metadata": {
        "id": "v0Enxgw4DJDD"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Train predictions\n",
        "knn_train_pred = knn_model.predict(X_smote_scaled)\n",
        "# training set recall\n",
        "knn_train_recall = recall(y_smote,knn_train_pred)\n",
        "knn_train_recall"
      ],
      "metadata": {
        "id": "pHRyxJFGDSpL"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Test predictions\n",
        "knn_test_pred = knn_model.predict(X_test_scaled)\n",
        "# Test recall\n",
        "knn_test_recall = recall(y_test,knn_test_pred)\n",
        "knn_test_recall"
      ],
      "metadata": {
        "id": "romm3zJvDSky"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Classification report\n",
        "print(classification_report(y_test,knn_test_pred))"
      ],
      "metadata": {
        "id": "3h8ibpdaDjRO"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Confusion matrix\n",
        "knn_confusion_matrix = cm(y_test, knn_test_pred)\n",
        "cm_display = cmd(confusion_matrix = knn_confusion_matrix, display_labels = [False, True])\n",
        "\n",
        "font = {'family' : 'DejaVu Sans',\n",
        "        'weight' : 'bold',\n",
        "        'size'   : 22}\n",
        "plt.rc('font', **font)\n",
        "\n",
        "cm_display.plot(cmap='Oranges')\n",
        "plt.title('Confusion matrix: K NEAREST NEIGHBORS')\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "qYGJyqdKDo7p"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### ML Model - 3 :Naive Bayes"
      ],
      "metadata": {
        "id": "Fze-IPXLpx6K"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# ML Model - 3 Implementation\n",
        "# Using stratified k fold cross validation so that each split\n",
        "# has almost equal proportion of classification results\n",
        "cv_method = RepeatedStratifiedKFold(n_splits=4,\n",
        "                                    n_repeats=3,\n",
        "                                    random_state=0)\n",
        "\n",
        "# Fit the Algorithm\n",
        "nb_model = GaussianNB()\n",
        "nb_params = {'var_smoothing': np.logspace(0,-9, num=100)\n",
        "             }\n",
        "# Predict on the model"
      ],
      "metadata": {
        "id": "FFrSXAtrpx6M"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "nb_gridsearch = GridSearchCV(nb_model,\n",
        "                             nb_params,\n",
        "                             cv=cv_method,\n",
        "                             scoring= 'recall')\n",
        "nb_gridsearch.fit(X_smote_scaled,y_smote)\n",
        "nb_best_params = nb_gridsearch.best_params_\n",
        "nb_best_params"
      ],
      "metadata": {
        "id": "-dalAX9-EPmf"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# building knn model with best parameters\n",
        "nb_model = GaussianNB(var_smoothing=nb_best_params['var_smoothing'])"
      ],
      "metadata": {
        "id": "ffyy4R-fEXeN"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# training the model\n",
        "nb_model.fit(X_smote_scaled, y_smote)"
      ],
      "metadata": {
        "id": "Pqc4m9nkEbCK"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Train predictions\n",
        "nb_train_pred = nb_model.predict(X_smote_scaled)\n",
        "# training set recall\n",
        "nb_train_recall = recall(y_smote,nb_train_pred)\n",
        "nb_train_recall"
      ],
      "metadata": {
        "id": "HREeVxkBEfUb"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Test predictions\n",
        "nb_test_pred = nb_model.predict(X_test_scaled)\n",
        "# Test recall\n",
        "nb_test_recall = recall(y_test,nb_test_pred)\n",
        "nb_test_recall\n"
      ],
      "metadata": {
        "id": "8JptYna4EfQj"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Classification report\n",
        "print(classification_report(y_test,nb_test_pred))"
      ],
      "metadata": {
        "id": "4dgS-9KBEfMS"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Confusion matrix\n",
        "nb_confusion_matrix = cm(y_test, nb_test_pred)\n",
        "cm_display = cmd(confusion_matrix = nb_confusion_matrix, display_labels = [False, True])\n",
        "\n",
        "font = {'family' : 'DejaVu Sans',\n",
        "        'weight' : 'bold',\n",
        "        'size'   : 22}\n",
        "plt.rc('font', **font)\n",
        "\n",
        "cm_display.plot(cmap='Oranges')\n",
        "plt.title('Confusion matrix: NAIVE BAYES')\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "mGWYqK-0E3kc"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "False negatives obtained after using Naive Bayes: 72"
      ],
      "metadata": {
        "id": "rSZ3HQo-E8X-"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "##ML Model -4: Decision tree"
      ],
      "metadata": {
        "id": "69BqKVieFPvV"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Max depth of dt without hyperparameter tuning = 28 and min samples leaf = 1\n",
        "dt_model = DecisionTreeClassifier()\n",
        "dt_params = {'max_depth':np.arange(1,10),\n",
        "             'min_samples_split':np.arange(0.1,1,0.1),\n",
        "             'min_samples_leaf':np.arange(0.1,0.6,0.1)\n",
        "             }\n"
      ],
      "metadata": {
        "id": "g7zVx3dAFO3c"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# using gridsearchcv to find best parameters\n",
        "dt_gridsearch = GridSearchCV(dt_model,\n",
        "                             dt_params,\n",
        "                             cv=cv_method,\n",
        "                             scoring= 'recall')\n",
        "dt_gridsearch.fit(X_smote,y_smote)\n",
        "dt_best_params = dt_gridsearch.best_params_\n",
        "dt_best_params"
      ],
      "metadata": {
        "id": "ud71VXhjGahF"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# building knn model with best parameters\n",
        "dt_model = DecisionTreeClassifier(max_depth=dt_best_params['max_depth'],\n",
        "                                  min_samples_split=dt_best_params['min_samples_split'],\n",
        "                                  min_samples_leaf=dt_best_params['min_samples_leaf'])\n",
        "\n",
        "dt_model.fit(X_smote_scaled, y_smote)"
      ],
      "metadata": {
        "id": "ukYNgGgOGhLM"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Train predictions\n",
        "dt_train_pred = dt_model.predict(X_smote_scaled)\n",
        "# training set recall\n",
        "dt_train_recall = recall(y_smote,dt_train_pred)\n",
        "dt_train_recall"
      ],
      "metadata": {
        "id": "7zZNziSmG2KS"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Test predictions\n",
        "dt_test_pred = dt_model.predict(X_test_scaled)\n",
        "# Test recall\n",
        "dt_test_recall = recall(y_test,dt_test_pred)\n",
        "dt_test_recall"
      ],
      "metadata": {
        "id": "LQW4Uo9cG2Gr"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Classification report\n",
        "print(classification_report(y_test,dt_test_pred))"
      ],
      "metadata": {
        "id": "Sk2hCO8yG2Cq"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "# Feature importances\n",
        "\n",
        "dt_feat_imp = pd.Series(dt_model.feature_importances_, index=X.columns)\n",
        "plt.figure(figsize=(10,5))\n",
        "plt.title('Feature Importances: DECISION TREE')\n",
        "plt.xlabel('Relative Importance')\n",
        "dt_feat_imp.nlargest(20).plot(kind='barh')"
      ],
      "metadata": {
        "id": "8lAAl7fAG1-X"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Only one feature (age) was given imporatance while fitting a decision tree model. This is because of max depth being 1.\n",
        "\n"
      ],
      "metadata": {
        "id": "wMDdprBxHKR-"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Confusion matrix\n",
        "dt_confusion_matrix = cm(y_test, dt_test_pred)\n",
        "cm_display = cmd(confusion_matrix = dt_confusion_matrix, display_labels = [False, True])\n",
        "\n",
        "font = {'family' : 'DejaVu Sans',\n",
        "        'weight' : 'bold',\n",
        "        'size'   : 22}\n",
        "plt.rc('font', **font)\n",
        "\n",
        "cm_display.plot(cmap='Oranges')\n",
        "plt.title('Confusion matrix: DECISION TREE')\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "WcqoHJ9kHNRv"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "##ML Model - 5: Random Forest\n"
      ],
      "metadata": {
        "id": "NBVjUyQ7Htmj"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "# random forest model\n",
        "rf_model = RandomForestClassifier(random_state=0)\n",
        "rf_params = {'n_estimators':[500],                    # limited due to computational power availability\n",
        "             'max_depth':np.arange(1,6),\n",
        "             'min_samples_split':np.arange(0.1,1,0.1),\n",
        "             'min_samples_leaf':np.arange(0.1,0.6,0.1)}"
      ],
      "metadata": {
        "id": "vRDn0xkfHrow"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# using gridsearchcv to find best parameters\n",
        "rf_gridsearch = GridSearchCV(rf_model,rf_params,cv=cv_method,scoring='recall')\n",
        "rf_gridsearch.fit(X_smote,y_smote)\n",
        "rf_best_params = rf_gridsearch.best_params_\n",
        "rf_best_params"
      ],
      "metadata": {
        "id": "flXGVvEIHtGF"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Fitting RF model with best parameters\n",
        "rf_model = RandomForestClassifier(n_estimators=rf_best_params['n_estimators'],\n",
        "                                  min_samples_leaf=rf_best_params['min_samples_leaf'],\n",
        "                                  min_samples_split=rf_best_params['min_samples_split'],\n",
        "                                  max_depth=rf_best_params['max_depth'],\n",
        "                                  random_state=0)\n",
        "\n",
        "# fit\n",
        "rf_model.fit(X_smote,y_smote)"
      ],
      "metadata": {
        "id": "C3KpjPi-IAbD"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# train predictions\n",
        "rf_train_pred = rf_model.predict(X_smote)\n",
        "# train recall\n",
        "rf_train_recall = recall(y_smote,rf_train_pred)\n",
        "rf_train_recall"
      ],
      "metadata": {
        "id": "CoZ1DoaHIL7p"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Test predictions\n",
        "rf_test_pred = rf_model.predict(X_test)\n",
        "# test recall\n",
        "rf_test_recall = recall(y_test,rf_test_pred)\n",
        "rf_test_recall"
      ],
      "metadata": {
        "id": "UOyYo6X5IL3y"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Classification report\n",
        "print(classification_report(y_test,rf_test_pred))"
      ],
      "metadata": {
        "id": "xJTlDEM7ILzF"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Feature importances\n",
        "\n",
        "rf_feat_imp = pd.Series(rf_model.feature_importances_, index=X.columns)\n",
        "plt.figure(figsize=(10,5))\n",
        "plt.title('Feature Importances: RANDOM FORESTS')\n",
        "plt.xlabel('Relative Importance')\n",
        "rf_feat_imp.nlargest(20).plot(kind='barh')"
      ],
      "metadata": {
        "id": "34v3Z91oIdz4"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Features other than age are also given importance in this case insted of just one feature in case of decision tree.\n",
        "\n",
        "But age still remains the most important feature in predicting the final outcome for random forests."
      ],
      "metadata": {
        "id": "p2YovDwoIhvS"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Confusion matrix\n",
        "rf_confusion_matrix = cm(y_test, rf_test_pred)\n",
        "cm_display = cmd(confusion_matrix = rf_confusion_matrix, display_labels = [False, True])\n",
        "\n",
        "font = {'family' : 'DejaVu Sans',\n",
        "        'weight' : 'bold',\n",
        "        'size'   : 22}\n",
        "plt.rc('font', **font)\n",
        "\n",
        "cm_display.plot(cmap='Oranges')\n",
        "plt.title('Confusion matrix: RANDOM FORESTS')\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "O3RVtNWuIoX0"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Plotting Recall scores\n",
        "\n",
        "ML_models = ['Logistic Regression','K Nearest Neighbors','Naive Bayes','Decision Tree','Random Forests']\n",
        "train_recalls = [lr_train_recall,knn_train_recall,nb_train_recall,dt_train_recall,rf_train_recall]\n",
        "test_recalls = [lr_test_recall,knn_test_recall,nb_test_recall,dt_test_recall,rf_test_recall]\n",
        "\n",
        "X_axis = np.arange(len(ML_models))\n",
        "\n",
        "plt.figure(figsize=(10,5))\n",
        "plt.barh(X_axis - 0.2, train_recalls, 0.4, label = 'Train Recall')\n",
        "plt.barh(X_axis + 0.2, test_recalls, 0.4, label = 'Test Recall')\n",
        "\n",
        "plt.yticks(X_axis,ML_models)\n",
        "plt.xlabel(\"Recall score\")\n",
        "plt.title(\"Recall score for each model\")\n",
        "plt.legend(bbox_to_anchor=(1.05, 1), loc='upper left',title='Legend')\n",
        "plt.show()\n"
      ],
      "metadata": {
        "id": "3CntFvK1I28v"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## ***8.*** ***Future Work (Optional)***"
      ],
      "metadata": {
        "id": "EyNgTHvd2WFk"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 1. Save the best performing ml model in a pickle file or joblib file format for deployment process.\n"
      ],
      "metadata": {
        "id": "KH5McJBi2d8v"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Save the File"
      ],
      "metadata": {
        "id": "bQIANRl32f4J"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 2. Again Load the saved model file and try to predict unseen data for a sanity check.\n"
      ],
      "metadata": {
        "id": "iW_Lq9qf2h6X"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Load the File and predict unseen data."
      ],
      "metadata": {
        "id": "oEXk9ydD2nVC"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### ***Congrats! Your model is successfully created and ready for deployment on a live server for a real user interaction !!!***"
      ],
      "metadata": {
        "id": "-Kee-DAl2viO"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Conclusion**"
      ],
      "metadata": {
        "id": "gCX9965dhzqZ"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Write the conclusion here."
      ],
      "metadata": {
        "id": "Fjb1IsQkh3yE"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### ***Hurrah! You have successfully completed your Machine Learning Capstone Project !!!***"
      ],
      "metadata": {
        "id": "gIfDvo9L0UH2"
      }
    }
  ]
}